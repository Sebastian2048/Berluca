# generador.py
import os
import glob 
import datetime
import re 
from collections import Counter, defaultdict
from typing import List, Tuple, Dict

# üì¶ Importaciones de configuraci√≥n y funciones de parseo
try:
    from config import (
        CARPETA_ORIGEN, CARPETA_SALIDA, LOGO_DEFAULT, LOGOS_CATEGORIA, 
        TITULOS_VISUALES, CATEGORIAS_PRINCIPALES_ESPANOL, CLAVES_ROLL_OVER
    )
    from clasificador import extraer_bloques_m3u, extraer_nombre_canal, extraer_url
except ImportError as e:
    print(f"Error al importar configuraci√≥n: {e}")
    # Definiciones de fallback si falla la importaci√≥n
    def extraer_bloques_m3u(lineas: List[str]): return []
    def extraer_nombre_canal(bloque: List[str]): return "Sin nombre"
    def extraer_url(bloque: List[str]): return ""
    CARPETA_ORIGEN = "Beluga/compilados"
    CARPETA_SALIDA = "Beluga"
    LOGO_DEFAULT = ""
    LOGOS_CATEGORIA = {}
    TITULOS_VISUALES = {}
    CATEGORIAS_PRINCIPALES_ESPANOL = []
    CLAVES_ROLL_OVER = {}


# Definici√≥n del archivo final PRINCIPAL
ARCHIVO_SALIDA_BASE = os.path.join(CARPETA_SALIDA, "RP_S2048.m3u")
PATRON_CORRELATIVO = os.path.join(CARPETA_SALIDA, "RP_S????.m3u")


# =========================================================================================
# üÜï FUNCIONES AUXILIARES
# =========================================================================================

def encontrar_siguiente_correlativo() -> str:
    """Busca archivos RP_S????.m3u y devuelve el siguiente n√∫mero disponible (a partir de 2049)."""
    archivos_existentes = glob.glob(PATRON_CORRELATIVO)
    numeros = []
    for archivo in archivos_existentes:
        nombre_base = os.path.basename(archivo)
        match = re.search(r'RP_S(\d{4})\.m3u', nombre_base)
        if match:
            try:
                num = int(match.group(1))
                if num >= 2049:
                    numeros.append(num)
            except ValueError:
                continue

    if not numeros:
        siguiente_numero = 2049
    else:
        siguiente_numero = max(numeros) + 1
        
    return f"RP_S{siguiente_numero:04d}.m3u"

def limpiar_archivos_temporales(ruta_archivos: str):
    """Elimina los archivos de compilados/ que no pertenecen al RP_S2048."""
    
    ruta_roll_over = os.path.join(CARPETA_ORIGEN, "roll_over_general.m3u")
    
    if os.path.exists(ruta_roll_over):
        try:
            os.remove(ruta_roll_over)
            print(f"üóëÔ∏è Archivo temporal {os.path.basename(ruta_roll_over)} eliminado.")
        except Exception as e:
            print(f"‚ö†Ô∏è No se pudo eliminar {os.path.basename(ruta_roll_over)}: {e}")


def reclasificar_roll_over(bloques: List[List[str]]) -> List[Tuple[str, List[str]]]:
    """
    Toma bloques y los clasifica en categor√≠as espec√≠ficas para el roll-over,
    usando CLAVES_ROLL_OVER.
    """
    bloques_clasificados = []
    
    for bloque in bloques:
        nombre = extraer_nombre_canal(bloque)
        nombre_lower = nombre.lower().replace("√±", "n").replace(".", "")
        
        categoria_asignada = None
        
        for categoria, claves in CLAVES_ROLL_OVER.items():
            if any(clave in nombre_lower for clave in claves):
                categoria_asignada = categoria 
                break
        
        if categoria_asignada:
            bloques_clasificados.append((categoria_asignada, bloque))
        else:
            # Si no coincide, va a la categor√≠a de √∫ltimo recurso del roll-over
            bloques_clasificados.append(("SIN_CLASIFICAR_ROLLOVER", bloque))
            
    return bloques_clasificados


# =========================================================================================
# üß± CONSOLIDACI√ìN DE LISTAS
# =========================================================================================

def consolidar_lista(rutas_archivos: List[str], ruta_salida: str, es_roll_over: bool) -> Tuple[int, Counter]:
    """L√≥gica unificada para generar la lista M3U principal."""
    
    rutas_archivos.sort(key=lambda x: os.path.basename(x))
    
    totales_por_categoria = Counter()
    total_consolidado = 0
    urls_por_nombre = defaultdict(set)
    urls_escritas_global = set()

    with open(ruta_salida, "w", encoding="utf-8", errors="ignore") as salida:
        salida.write("#EXTM3U\n\n")

        for ruta in rutas_archivos:
            archivo_base = os.path.basename(ruta)
            nombre_categoria_snake = archivo_base.replace(".m3u", "")
            
            # T√≠tulos para RP_S2048.m3u
            titulo_visual = TITULOS_VISUALES.get(nombre_categoria_snake, f"‚òÖ {nombre_categoria_snake.replace('_', ' ').upper()} ‚òÖ")
            logo = LOGOS_CATEGORIA.get(nombre_categoria_snake, LOGO_DEFAULT)
            
            salida.write(f"\n# ====== {titulo_visual} ======\n\n")

            try:
                with open(ruta, "r", encoding="utf-8", errors="ignore") as f:
                    lineas = f.readlines()
                    bloques = extraer_bloques_m3u(lineas)
            except Exception: continue

            bloques_escritos_en_categoria = 0
            
            for bloque in bloques:
                nombre = extraer_nombre_canal(bloque)
                url = extraer_url(bloque)
                nombre_clave = nombre.strip().lower().replace(" ", "")

                if url in urls_escritas_global: continue 
                if len(urls_por_nombre[nombre_clave]) >= 2: continue

                if url:
                    # Usamos el t√≠tulo del bloque para group-title
                    extinf_line = f'#EXTINF:-1 tvg-logo="{logo}" group-title="{titulo_visual}",{nombre.strip()}'
                    salida.write(extinf_line + "\n")
                    salida.write(f"{url.strip()}\n\n")
                    
                    urls_escritas_global.add(url)
                    urls_por_nombre[nombre_clave].add(url)
                    total_consolidado += 1
                    bloques_escritos_en_categoria += 1
            
            if bloques_escritos_en_categoria > 0:
                totales_por_categoria[nombre_categoria_snake] += bloques_escritos_en_categoria
                
    return total_consolidado, totales_por_categoria


def consolidar_lista_reclasificada(bloques_por_subcategoria: defaultdict[str, List[List[str]]], ruta_salida: str) -> Tuple[int, Counter]:
    """
    Escribe el archivo roll-over (RP_Sxxxx.m3u) usando las nuevas sub-categor√≠as.
    """
    
    totales_por_categoria = Counter()
    total_consolidado = 0
    urls_escritas_global = set()
    
    # Ordenar las sub-categor√≠as seg√∫n las claves de CLAVES_ROLL_OVER para una mejor presentaci√≥n
    orden_claves = list(CLAVES_ROLL_OVER.keys()) + ["SIN_CLASIFICAR_ROLLOVER"]
    categorias_a_escribir = [c for c in orden_claves if c in bloques_por_subcategoria]

    with open(ruta_salida, "w", encoding="utf-8", errors="ignore") as salida:
        salida.write("#EXTM3U\n\n")

        for nombre_categoria_snake in categorias_a_escribir:
            
            # Usar el t√≠tulo visual definido para la sub-categor√≠a
            titulo_visual = TITULOS_VISUALES.get(nombre_categoria_snake, f"‚òÖ {nombre_categoria_snake.replace('_', ' ').upper()} ‚òÖ")
            logo = LOGO_DEFAULT 
            
            salida.write(f"\n# ====== {titulo_visual} ======\n\n")

            bloques_escritos_en_categoria = 0
            
            for bloque in bloques_por_subcategoria[nombre_categoria_snake]:
                nombre = extraer_nombre_canal(bloque)
                url = extraer_url(bloque)
                
                if url in urls_escritas_global: continue 
                
                if url:
                    extinf_line = f'#EXTINF:-1 tvg-logo="{logo}" group-title="{titulo_visual}",{nombre.strip()}'
                    salida.write(extinf_line + "\n")
                    salida.write(f"{url.strip()}\n\n")
                    
                    urls_escritas_global.add(url)
                    total_consolidado += 1
                    bloques_escritos_en_categoria += 1
            
            if bloques_escritos_en_categoria > 0:
                totales_por_categoria[nombre_categoria_snake] += bloques_escritos_en_categoria
                
    return total_consolidado, totales_por_categoria


# =========================================================================================
# üì¶ FUNCI√ìN PRINCIPAL DE CONSOLIDACI√ìN
# =========================================================================================

def generar_listas_finales():
    """
    Genera RP_S2048.m3u con categor√≠as de habla hispana, 
    y RP_Sxxxx.m3u con el contenido re-clasificado de roll_over_general.
    """
        
    print("\nüì¶ Iniciando consolidaci√≥n con deduplicaci√≥n y gesti√≥n de respaldos...")

    patron_busqueda = os.path.join(CARPETA_ORIGEN, "*.m3u")
    listas_clasificadas = glob.glob(patron_busqueda)
    
    # 1. Archivos para RP_S2048.m3u (SOLO ESPA√ëOL/PRINCIPAL)
    listas_principal = [
        ruta for ruta in listas_clasificadas 
        if os.path.basename(ruta).replace(".m3u", "") in CATEGORIAS_PRINCIPALES_ESPANOL
    ]
    
    ruta_roll_over = os.path.join(CARPETA_ORIGEN, "roll_over_general.m3u")
    
    # ------------------- A. Generar RP_S2048.m3u (Principal) -------------------
    
    total_consolidado_principal, totales_principal = consolidar_lista(
        listas_principal, ARCHIVO_SALIDA_BASE, es_roll_over=False
    )

    print(f"\n‚úÖ {os.path.basename(ARCHIVO_SALIDA_BASE)} generado con √©xito.")
    print(f"üìÅ Ubicaci√≥n: {ARCHIVO_SALIDA_BASE}")
    print(f"üìä Total de enlaces consolidados (ESPA√ëOL): {total_consolidado_principal}")
    print("üìä Totales por categor√≠a (Principal):")
    for cat, count in totales_principal.most_common():
        print(f"   -> {cat.replace('_', ' ').title()}: {count} enlaces")

    # ------------------- B. Generar RP_Sxxxx.m3u (Roll-Over/Correlativo) -------------------

    if os.path.exists(ruta_roll_over):
        
        with open(ruta_roll_over, "r", encoding="utf-8", errors="ignore") as f:
            lineas_roll_over = f.readlines()
        
        bloques_roll_over = extraer_bloques_m3u(lineas_roll_over)
        
        if bloques_roll_over:
            
            # 1. RE-CLASIFICAR el contenido de roll_over_general
            bloques_reclasificados = reclasificar_roll_over(bloques_roll_over)
            
            # 2. Organizar por las nuevas sub-categor√≠as
            bloques_por_subcategoria = defaultdict(list)
            for categoria, bloque in bloques_reclasificados:
                bloques_por_subcategoria[categoria].append(bloque)

            # 3. Generar la lista final
            archivo_correlativo = encontrar_siguiente_correlativo()
            ruta_correlativa = os.path.join(CARPETA_SALIDA, archivo_correlativo)

            total_consolidado_roll_over, totales_roll_over = consolidar_lista_reclasificada(
                bloques_por_subcategoria, ruta_correlativa
            )

            print(f"\n‚úÖ {archivo_correlativo} (Roll-Over/No Espa√±ol) generado con √©xito.")
            print(f"üìÅ Ubicaci√≥n: {ruta_correlativa}")
            print(f"üìä Total de enlaces consolidados: {total_consolidado_roll_over}")
            print("üìä Totales por sub-categor√≠a (Respaldo):")
            for cat, count in totales_roll_over.most_common():
                print(f"   -> {cat.replace('_', ' ').title()}: {count} enlaces")
        else:
            print("‚ö†Ô∏è roll_over_general.m3u est√° vac√≠o. No se genera archivo correlativo.")
        
        # 4. Eliminar roll_over_general.m3u
        limpiar_archivos_temporales(ruta_roll_over)
    else:
        print("‚ÑπÔ∏è No se encontr√≥ roll_over_general.m3u. No se genera archivo correlativo.")


if __name__ == "__main__":
    generar_listas_finales()